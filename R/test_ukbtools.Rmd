---
title: "test_ukbtools_and ukbwranglr"
output: html_notebook
---

```{r setup}
library(ukbwranglr)
library(ukbtools)
library(configr)
library(tidyverse)

# Constants
config <- read.config("../config.ini")
DUMMY_DATA_PATH <- paste0("../", config$PATHS$DUMMY_DATA_PATH)
UKB_DATA_CODING_6 <- paste0(config$PATHS$UKB_DATA_CODING_6)

# Load data
dummy_data_dict <- ukbwranglr::pheno_data_dict(DUMMY_DATA_PATH, delim = ",")
dummy_ukb_data <- ukbwranglr::read_pheno(DUMMY_DATA_PATH, dummy_data_dict, delim = ",") 
dummy_ukb_data$eid <- as.character(seq(1:nrow(dummy_ukb_data)))
self_report_icd_map <- read_delim(UKB_DATA_CODING_6, delim = "\t", col_types = cols(.default = "c"))
ukb_codings <- data.table::fread(
    "https://biobank.ctsu.ox.ac.uk/~bbdatan/Codings.tsv",
    colClasses = c('character'),
    sep = "\t",
    quote = " ",
    na.strings = c("", "NA")
  )
```

# ukbtools

```{r}
path_to_example_data <- system.file("extdata", package = "ukbtools")
my_ukb_data <- ukb_df("ukbxxxx", path = path_to_example_data)
```

```{r}
mapper <- ukb_df_field("ukbxxxx", path = path_to_example_data)
```

```{r}
ukb_context(data = my_ukb_data, subset.var = my_ukb_data$sex_f31_0_0 == "Male")

# ukb_context(data = test_read_pheno, subset.var = test_read_pheno$sex_f31_0_0 == "Male")
# 
# ukb_context(data = test_read_pheno, subset.var = (test_read_pheno$systolic_brachial_blood_pressure_during_pwa_f12674_2_0 > 120))
```

```{r}
# icd codes
ukb_icd_diagnosis(data = test_read_pheno, id = "2928752", icd.version = 10)
```


# ukbwranglr

## Functions

### Make pheno_data_dict

````{r}
small_file_path <- "/Users/alasdair/OneDrive - University College London/Lenovo backup 181219/WellcomePhD/Year2/ukbiobank/ukb_dr_gwas/data/ukb_main_filter.txt"

big_file_path <- "/Users/alasdair/Documents/Data/UKB/ICS/raw/ukb29341_29374_34321_37340_37076_37077_37079_37080_37755.txt"

data_dict <- pheno_data_dict(small_file_path)

# data_dict_filter <- data_dict[1:10,]

test_read_pheno <- read_pheno(small_file_path, pheno_data_dict = data_dict)
```

```{r}
# FOR TESTING BIGGER UKB PHENO FILE
# data_dict <- pheno_data_dict(big_file_path)
# 
# data_dict_filter <- data_dict[1:2000,]
# 
# test_read_pheno <- read_pheno(big_file_path, pheno_data_dict = data_dict_filter)
```

### Mutate DOB

```{r}
ukb_main_filter_parsed_CLEAN <- ukb_mutate_dob(ukb_df = test_read_pheno,
                                        ukb_mapping_df = data_dict)
```

### Numerical means col summaries (uses `rowMeans()`)

```{r}
system.time(
  ukb_main_filter_parsed_CLEAN_summary_cols <- ukb_mutate_numerical_means(ukb_df = ukb_main_filter_parsed_CLEAN, 
                                                                        ukb_mapping_df = data_dict)
)
```

### Rowise colsummarise (uses `apply()`)

Notes:

- Generating custom summary functions:
  
  - Make sure they include '...' as an argument, otherwise will get an 'unused argument' error, for example if supplying `na.rm = TRUE`
  - Beware rows with only `NA` values

```{r}
# need to add '...' to avoid throwing an error with na.rm ('unused argument')
n_not_na <- function(x, ...) {
  sum(!is.na(x))
}

summarise_test_read_pheno <- summarise_rowise(
  ukb_pheno = test_read_pheno,
  functions = c("mean", "sd", "n_not_na"),
  data_dict = data_dict,
  grouping_col = "Field_FieldID",
  selected_col_groups = data_dict %>% 
    dplyr::filter(ValueType %in% c("Continuous", "Integer")) %>% 
    .$Field_FieldID %>% 
    unique(),
  na.rm = TRUE
)

summarise_numerical_test_read_pheno_mean <-
  summarise_rowise_numerical_mean_min_max(ukb_pheno = test_read_pheno,
                                          ukb_mapping_df = data_dict,
                                          mean_min_max = "rowMeans")

summarise_numerical_test_read_pheno_min <-
  summarise_rowise_numerical_mean_min_max(ukb_pheno = test_read_pheno,
                                          ukb_mapping_df = data_dict,
                                          mean_min_max = "pmin")

summarise_numerical_test_read_pheno_max <-
  summarise_rowise_numerical_mean_min_max(ukb_pheno = test_read_pheno,
                                          ukb_mapping_df = data_dict,
                                          mean_min_max = "pmax")
```

```{r}
# number of noncancer diagnoses
test_noncancer <- summarise_rowise(
  ukb_pheno = test_read_pheno,
  functions = c("n_not_na"),
  data_dict = data_dict,
  grouping_col = "Field_FieldID",
  selected_col_groups = data_dict %>% 
    dplyr::filter(FieldID == 20002) %>% 
    .$Field_FieldID %>% 
    unique(),
  na.rm = TRUE
)

# eid with many diagnoses
id <- test_noncancer %>% 
  dplyr::arrange(desc(n_not_na_noncancer_illness_code_selfreported_20002)) %>% 
  .$eid %>% 
  head(n = 1)

# code adapted from ukbtools
individual_codes <- test_read_pheno %>%
      dplyr::filter(eid %in% id) %>%
      dplyr::select(
        tidyselect::contains("noncancer_illness")) %>%
      t() %>%
      tibble::as_tibble() %>%
      tidyr::drop_na()

colnames(individual_codes) <- id

# ...now make dummy icd10 data and use ukbtools to convert to icd10 meanings
test_icd10 <- data.frame("3366654" = c("E14", "E13", "E12"))
test <- test_icd10 %>%
  purrr::map( ~ ukb_icd_code_meaning(c(.), 10)) %>%
  dplyr::bind_rows(.id = "sample")
```


## Diabetes 

Compare ascertainment and dates of diagnosis using first-occurrence vs self-report data

### First occurrence

#### Numbers of different diabetes types (will include overlap)

```{r}
# source("utils.R")

test_read_pheno %>% 
  dplyr::select(tidyselect::contains("first_reported")) %>% 
  dplyr::select(tidyselect::contains("diabetes")) %>% 
  my_skim() %>% 
  dplyr::mutate(n_not_missing = 502521 - n_missing)
```

#### Mutate indicator column and assess DM numbers

```{r}
test_read_pheno <- diabetes_type_first_occurrence(test_read_pheno, data_dict)

table(test_read_pheno$diabetes_type_first_occurrence)
```

#### Date of diagnosis

- Earliest date across all first occurrence fields

```{r}
diabetes_dates <- test_read_pheno %>% 
  dplyr::select(tidyselect::contains("first_reported")) %>% 
  dplyr::select(tidyselect::contains("diabetes")) %>%
  names()

test <- rowise_min_max_date(test_read_pheno, selected_date_cols = diabetes_dates, new_colname = "test", min_max = "pmin")
```

```{r}
# test it removes dates correctly
test <- test_read_pheno %>% 
  dplyr::select("eid", tidyselect::contains("first_reported")) %>% 
  dplyr::select("eid", tidyselect::contains("diabetes"))

test[date_e11_first_reported_noninsulindependent_diabetes_mellitus_f130708_0_0 > lubridate::as_date("1995-01-01"), date_e11_first_reported_noninsulindependent_diabetes_mellitus_f130708_0_0 := lubridate::as_date("2037-07-07")]

test %>% my_skim()
```

```{r}
test2 <- rowise_min_max_date(test, selected_date_cols = diabetes_dates, new_colname = "test2", min_max = "pmax")


# needed to load dt+rowise_fn to global environment
test2[, n_not_na_dm := purrr::map(
      "n_not_na",
      dt_rowwise_fn,
      .SD), .SDcols = diabetes_dates]

test3 <- rowise_min_max_date(test2, selected_date_cols = diabetes_dates, new_colname = "testmin", min_max = "pmin")

# now use actual dm_date function
test4 <- diabetes_diagnosis_date_first_occurrence(test3, data_dict)

all(test4$diabetes_diagnosis_date_first_occurrence == test4$testmin, na.rm = TRUE)

test5 <- rowise_summary(ukb_pheno = test4, function_name = "n_not_na", selected_cols = diabetes_dates, new_colname = "rowise_test")
```


### Self-report

- Get FieldID's 20002, 20008 and 20009 separately
- Pivot longer
- row_bind
- join with ICD codes

```{r}
# cols for fieldid 20002
test_self_report <- dummy_ukb_data %>%
  select(eid,
         all_of(
           get_colname(field_id = "20002",
                       ukb_mapping_df = dummy_data_dict)
         ))

# get ukb_codings - TODO MAKE FUNCTION TO EXTRACT CODING FOR FIELDID (what if returns NULL?)
f20002_codings <- ukb_codings %>% 
  filter(Coding == (dummy_data_dict %>% filter(FieldID == "20002") %>% .$Coding %>% head(n = 1)))

# pivot longer - includes extra cols for manual checking
test_self_report_long <- test_self_report %>% 
  pivot_longer(
    cols = all_of(get_colname(field_id = "20002", ukb_mapping_df = dummy_data_dict)),
    # values_drop_na = TRUE
  ) %>% 
  left_join(f20002_codings, by = c("value" = "Meaning")) %>% 
  select(eid, coding = Value, value) %>% 
  left_join(self_report_icd_map, by = "coding") %>% 
  rename(code = meaning) %>% 
  left_join(icd10codes, by = "code")

# now without extra cols, as function
self_report_to_icd10 <- function(ukb_pheno,
                                 field_id,
                                 data_dict,
                                 ukb_codings, 
                                 self_report_icd_map) {
  
  selected_cols <- get_colname(field_id = field_id,
                       ukb_mapping_df = data_dict)
  
  ukb_pheno <- ukb_pheno %>%
  select(eid,
         all_of(selected_cols))
  
  field_id_codings <- ukb_codings %>% 
  filter(Coding == (data_dict %>% 
                      filter(FieldID == field_id) %>% 
                      .$Coding %>% 
                      head(n = 1)))
  
  ukb_pheno <- ukb_pheno %>% 
    pivot_longer(
      cols = all_of(selected_cols),
      values_to = paste(paste0("f", field_id), "value", sep = "_")
    ) %>% 
    mutate(instance_array = colname_to_field_inst_array_df(name)$instance_array)
}

test_self_report_long <- self_report_to_icd10(ukb_pheno = dummy_ukb_data, 
                     field_id = "20002", 
                     data_dict = dummy_data_dict, 
                     ukb_codings = ukb_codings, 
                     self_report_icd_map = self_report_icd_map)

# now multiple field_ids
fields_ids <- c("20002", "20008", "20009")

test <- fields_ids %>% 
  map(self_report_to_icd10, ukb_pheno = dummy_ukb_data,
                     data_dict = dummy_data_dict, 
                     ukb_codings = ukb_codings, 
                     self_report_icd_map = self_report_icd_map) %>% 
  reduce(inner_join, by = c("eid", "instance_array"))

  # %>% 
  #   left_join(field_id_codings, by = c("value" = "Meaning")) %>% 
  #   select(eid, coding = Value) %>% 
  #   left_join(self_report_icd_map, by = "coding") %>% 
  #   rename(icd10code = meaning)
```

```{r}
# delete soon!
# make function to extract field_id, instance, array from colnames
# descriptive_names <- names(dummy_ukb_data)[2:4]
# 
# test <- str_extract(descriptive_names, pattern = "_f[:digit:]+_[:digit:]+_[:digit:]+$") %>% 
#   str_sub(3L, -1L)
#   
# test <- tibble(fieldid_instance_array = test)
# 
# test <- test %>% 
#   separate(col = "fieldid_instance_array", 
#            into = c("fieldid", "instance", "array"), 
#            sep = "_", 
#            remove = FALSE) %>% 
#   mutate(
#     fieldid_instance = paste(fieldid, instance, sep = "_"),
#     instance_array = paste(instance, array, sep = "_"))
```


TODO  - how many unspecified first occurrence dm have self-reported T1 vs T2 DM?

# TESTS

<!-- ## Rowise summaries -->

<!-- ```{r} -->
<!-- copy_test_read_pheno <- test_read_pheno -->
<!-- ``` -->

<!-- ### rough idea for one function to one set of cols -->

<!-- ```{r} -->
<!-- # job list -->
<!-- functions <- c('mean') -->
<!-- columns <- test_read_pheno %>%  -->
<!--   dplyr::select(systolic_blood_pressure_automated_reading_f4080_0_0:systolic_blood_pressure_automated_reading_f4080_3_1) %>% -->
<!--   names() -->
<!-- column_group_name <- "f4080" -->
<!-- new_columns = paste(functions, column_group_name, sep = "_") -->

<!-- job_list <- list(columns, new_columns) -->
<!-- names(job_list) <- c('columns', 'new_columns') -->

<!-- # rowwise function -->
<!-- rowwise_fn <- function(fn, cols, ...) { -->
<!--   apply(cols, MARGIN = 1, fn, ...) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- message("New cols na.rm = TRUE") -->
<!-- test_read_pheno[, job_list$new_columns := purrr::map(functions, rowwise_fn, .SD, na.rm = TRUE), .SDcols = job_list$columns] -->
<!-- head(test_read_pheno$mean_f4080) -->

<!-- test_read_pheno <- copy_test_read_pheno -->

<!-- message("New cols na.rm = FALSE") -->
<!-- test_read_pheno[, job_list$new_columns := purrr::map(job_list$functions, rowwise_fn, .SD, na.rm = FALSE), .SDcols = job_list$columns] -->
<!-- head(test_read_pheno$mean_f4080) -->
<!-- ``` -->

<!-- #### Benchmark - compare rowMeans() with apply() -->

<!-- - rowMeans() is ~50x faster -->

<!-- ```{r} -->
<!-- # benchmark - apply -->
<!-- test_read_pheno <- copy_test_read_pheno -->
<!-- system.time( -->
<!--   test_read_pheno[, job_list$new_columns := purrr::map(functions, rowwise_fn, .SD, na.rm = TRUE), .SDcols = job_list$columns] -->
<!--   ) -->
<!-- head(test_read_pheno$mean_f4080) -->

<!-- # benchmark - rowmeans -->
<!-- test_read_pheno <- copy_test_read_pheno -->
<!-- system.time( -->
<!--   test_read_pheno2 <- test_read_pheno %>% -->
<!--     dplyr::mutate(new_mean_col = rowMeans(dplyr::across(tidyselect::all_of(job_list$columns)), -->
<!--                                      na.rm = TRUE)) -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # now multiple functions -->
<!-- functions <- c('mean', 'sd') -->
<!-- new_columns = paste(functions, column_group_name, sep = "_") -->
<!-- job_list <- list(columns, new_columns) -->
<!-- names(job_list) <- c('columns', 'new_columns') -->

<!-- # benchmark - apply -->
<!-- system.time( -->
<!--   test_read_pheno[, job_list$new_columns := purrr::map(functions, rowwise_fn, .SD, na.rm = TRUE), .SDcols = job_list$columns] -->
<!--   ) -->
<!-- head(test_read_pheno$mean_f4080) -->

<!-- # benchmark - rowmeans -->
<!-- test_read_pheno <- copy_test_read_pheno -->
<!-- system.time( -->
<!--   test_read_pheno2 <- test_read_pheno %>% -->
<!--     dplyr::mutate(new_mean_col = rowMeans(dplyr::across(tidyselect::all_of(job_list$columns)), -->
<!--                                      na.rm = TRUE)) -->
<!-- ) -->
<!-- ``` -->


<!-- ### now apply to multiple groups of columns -->

<!-- ```{r} -->
<!-- # job list -->
<!-- functions <- c('mean', 'sd') -->
<!-- columns_diastolic <- test_read_pheno %>%  -->
<!--   dplyr::select(diastolic_blood_pressure_automated_reading_f4079_0_0:diastolic_blood_pressure_automated_reading_f4079_3_1) %>%  -->
<!--   names() -->
<!-- column_group_name <- "f4079" -->
<!-- new_columns = paste(functions, column_group_name, sep = "_") -->

<!-- job_list_distolic <- list(columns_diastolic, new_columns) -->
<!-- names(job_list_distolic) <- c('columns_diastolic', 'new_columns') -->

<!-- job_list_of_lists <- list(job_list, job_list_distolic) -->

<!-- names(job_list_of_lists) <- c("systolic", "diastolic") -->

<!-- for (i in seq_along(job_list_of_lists)) { -->
<!--   print(names(job_list_of_lists[[i]])) -->
<!-- } -->

<!-- for (id in job_list_of_lists) { -->
<!--   print(id) -->
<!-- } -->


<!-- pb <- progress::progress_bar$new(format = "[:bar] :current/:total (:percent)", -->
<!--                                    total = length(job_list_of_lists)) -->
<!-- pb$tick(0) -->

<!-- for (i in seq_along(job_list_of_lists)) { -->
<!--   pb$tick(1) -->
<!--   test_read_pheno[, job_list_of_lists[[i]]$new_columns := purrr::map(functions, rowwise_fn, .SD, na.rm = TRUE), .SDcols = job_list_of_lists[[i]]$columns] -->
<!-- } -->
<!-- ``` -->



